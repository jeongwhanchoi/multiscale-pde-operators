defaults:
  - _train
  - _self_
  - dataset: magnetostatics

model_cfg:
  operator:
    _target_: multiscale_operator.operators.mesh_graph_net.EncoderProcessorDecoder
    num_message_passing: 15
    hidden_size: 64

data_transform:
  _target_: multiscale_operator.transforms.chain_transforms.ChainedTransforms
  transforms:
    - _target_: multiscale_operator.transforms.tree_op_transform.TreeOpTransform
      k_hop_levels: 2
      n_levels: 4
      k_neighbors: 8
    - _target_: multiscale_operator.transforms.relative_position.RelativePositionTransform

train_cfg:
  batch_size: 48
  accumulate_grad_batches: 1

wandb:
  group: final_deeptree_${dataset.name}
  tags: [deeptree, final, '${dataset.name}']

plot_every_n_batches: 1  # = 3*16
